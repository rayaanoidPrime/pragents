{
  "name": "1 workflow",
  "nodes": [
    {
      "parameters": {
        "language": "python",
        "pythonCode": "import json\nfrom datetime import datetime\n\n# Define roles and responsibilities for each agent\n\n# Process each input item\nresults = []\nagent_roles = {}\nselected_ids = []\nquery = \"\"\n\npreviousStartData = _(\"start\").all();\nfor item in previousStartData:\n  itemDict = item.json.to_py()\n  # print(f\"Json Body ======>> {itemDict.get('body').get('selectedAgentIds')}\")\n  selected_ids.append(itemDict.get('body').get('selectedAgentIds'))\n  query = itemDict.get('body').get('query')\n\nprint(f\"selected_idsselected_ids {selected_ids} queryquery {query}\")\n\nextracttData = _(\"extract\").all();\nfor item in extracttData:\n  itemDict = item.json.to_py()\n  id = itemDict.get('data').get('id')\n  title = itemDict.get('data').get('title')\n  prompt = itemDict.get('data').get('prompt')\n  # print(f\"EXTRACT Body ======>> {itemDict.get('data').get('id')}\")\n  agent_roles[id] = prompt\n\n# print(f\"agent_roles {agent_roles.get('data-engineer')}\")\n\nrole_descriptions = \"\\n\\n\".join([\n    f\"Agent ID: {aid}\\n{agent_roles.get(aid, f'Unknown agent: {aid}')}\"\n    for aid in selected_ids[0]\n])\n\nprompt = f\"\"\"You are a multi-agent data engineering system that simulates multiple expert agents collaborating together. Based on the selected agents, you'll provide comprehensive solutions that blend expertise from all selected specialists.\n\nCurrently, you are acting as these experts:\n{selected_ids[0]}\n\nROLE DESCRIPTIONS:\n{role_descriptions}\n\nFor your response:\n1. Structure your answer to clearly show which expert is providing which part of the solution\n2. Include practical implementation details and examples where appropriate\n3. Address scalability, reliability, and performance considerations\n4. If relevant, include sample architecture diagrams described in text format\n5. Provide configurations or flow diagram when they would be helpful\n6. DO NOT Provide Code Snippets, unless explicitly asked for but Focus more on Content\n\nRemember: Focus on providing actionable advice that directly addresses the query without any unnecessary introductions.\n\nUser Query: {query}\n\"\"\"\n\nitem.json[\"prompt\"] = prompt\nresults.append(item)\n\nreturn results"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2260,
        1380
      ],
      "id": "11ef38c9-f240-42d8-b41e-f7cbd6e5f432",
      "name": "Process Agent Request"
    },
    {
      "parameters": {
        "respondWith": "allIncomingItems",
        "options": {}
      },
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.1,
      "position": [
        1900,
        820
      ],
      "id": "0b32d575-1bb8-460d-8b9c-37b607777f89",
      "name": "Respond to Webhook"
    },
    {
      "parameters": {
        "aggregate": "aggregateAllItemData",
        "destinationFieldName": "context",
        "options": {}
      },
      "id": "a8502f19-6f41-48de-800c-72af0808f278",
      "name": "Aggregate",
      "type": "n8n-nodes-base.aggregate",
      "position": [
        -740,
        960
      ],
      "typeVersion": 1,
      "alwaysOutputData": true
    },
    {
      "parameters": {
        "content": "Get Context",
        "height": 537,
        "width": 755,
        "color": 7
      },
      "id": "ccddd2bb-5459-4e83-b39b-5fc1f31d6412",
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -1280,
        740
      ],
      "typeVersion": 1
    },
    {
      "parameters": {
        "options": {}
      },
      "id": "20267b49-6e29-460e-87c6-a3082b6d1356",
      "name": "Chat Memory Manager",
      "type": "@n8n/n8n-nodes-langchain.memoryManager",
      "position": [
        -1120,
        960
      ],
      "typeVersion": 1,
      "alwaysOutputData": true
    },
    {
      "parameters": {
        "sessionIdType": "customKey",
        "sessionKey": "data_agent_conversation_X112n997y"
      },
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "typeVersion": 1.3,
      "position": [
        -880,
        1620
      ],
      "id": "a1b797c4-9904-422a-a955-547ca574c619",
      "name": "Window Buffer Memory"
    },
    {
      "parameters": {
        "public": true,
        "options": {
          "loadPreviousSession": "memory"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "typeVersion": 1.1,
      "position": [
        -1720,
        760
      ],
      "id": "859a839a-3a40-4af2-a7a1-a6d781dfddeb",
      "name": "Chat Trigger",
      "webhookId": "b2f479b7-83af-4ddf-a494-621127b5f96c"
    },
    {
      "parameters": {
        "mode": "insert",
        "messages": {
          "messageValues": [
            {
              "type": "user",
              "message": "={{ $('start').item.json.body.query }}"
            },
            {
              "type": "ai",
              "message": "={{ $json.output.summary }}"
            }
          ]
        }
      },
      "id": "81258ae9-095d-4c22-86a2-fe7e0bfac38a",
      "name": "Insert Chat",
      "type": "@n8n/n8n-nodes-langchain.memoryManager",
      "position": [
        1680,
        120
      ],
      "typeVersion": 1,
      "alwaysOutputData": true
    },
    {
      "parameters": {
        "content": "## Save Context",
        "height": 251,
        "width": 441,
        "color": 6
      },
      "id": "2678aab1-6809-4a44-8399-22c77ce08568",
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -1040,
        1540
      ],
      "typeVersion": 1
    },
    {
      "parameters": {
        "content": "### The \"Get Chat,\" \"Insert Chat,\" and \"Window Buffer Memory\" nodes will help the LLM model maintain context throughout the conversation.",
        "height": 91.01435855269375,
        "width": 487.4293487597613,
        "color": 6
      },
      "id": "ea143540-c79e-4796-90c3-a3ce4b6b2526",
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -1260,
        780
      ],
      "typeVersion": 1
    },
    {
      "parameters": {
        "multipleMethods": true,
        "httpMethod": [
          "POST",
          "GET"
        ],
        "path": "dataengineering-common",
        "responseMode": "responseNode",
        "options": {
          "responseHeaders": {
            "entries": [
              {
                "name": "Access-Control-Allow-Origin",
                "value": "*"
              }
            ]
          }
        }
      },
      "id": "112abbe2-716e-494e-afc0-a3ab53a64536",
      "name": "start",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [
        -3300,
        1620
      ],
      "webhookId": "87f6c8c3-55de-4661-8fd9-2727490b076f"
    },
    {
      "parameters": {
        "fileSelector": "/data/avatars/*.json",
        "options": {}
      },
      "type": "n8n-nodes-base.readWriteFile",
      "typeVersion": 1,
      "position": [
        -2920,
        1280
      ],
      "id": "8e05a504-fcd1-4319-9aaf-8db221719133",
      "name": "Read/Write Files from Disk",
      "alwaysOutputData": true
    },
    {
      "parameters": {
        "operation": "fromJson",
        "options": {}
      },
      "type": "n8n-nodes-base.extractFromFile",
      "typeVersion": 1,
      "position": [
        -2720,
        1280
      ],
      "id": "8561e860-8077-45af-8d4e-b821054e59bf",
      "name": "extract"
    },
    {
      "parameters": {
        "rules": {
          "values": [
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 2
                },
                "conditions": [
                  {
                    "leftValue": "={{ $('start').item.json.body.modelType }}",
                    "rightValue": "openai",
                    "operator": {
                      "type": "string",
                      "operation": "equals"
                    },
                    "id": "62cfde5c-a347-4d09-ac54-58666db166fd"
                  }
                ],
                "combinator": "and"
              },
              "renameOutput": true,
              "outputKey": "openai"
            },
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 2
                },
                "conditions": [
                  {
                    "id": "abf337b7-fc5b-4136-a843-19cd82359f8f",
                    "leftValue": "={{ $('start').item.json.body.modelType }}",
                    "rightValue": "claude",
                    "operator": {
                      "type": "string",
                      "operation": "equals",
                      "name": "filter.operator.equals"
                    }
                  }
                ],
                "combinator": "and"
              },
              "renameOutput": true,
              "outputKey": "claude"
            },
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 2
                },
                "conditions": [
                  {
                    "id": "9f6b39b6-4bf4-4942-825c-1f469a00220e",
                    "leftValue": "={{ $('start').item.json.body.modelType }}",
                    "rightValue": "ollama",
                    "operator": {
                      "type": "string",
                      "operation": "equals",
                      "name": "filter.operator.equals"
                    }
                  }
                ],
                "combinator": "and"
              },
              "renameOutput": true,
              "outputKey": "ollama"
            },
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 2
                },
                "conditions": [
                  {
                    "id": "4787cde4-1838-4a03-bea9-232d49f6df77",
                    "leftValue": "={{ $('start').item.json.body.modelType }}",
                    "rightValue": "default",
                    "operator": {
                      "type": "string",
                      "operation": "equals",
                      "name": "filter.operator.equals"
                    }
                  }
                ],
                "combinator": "and"
              },
              "renameOutput": true,
              "outputKey": "defaultoopenai"
            },
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 2
                },
                "conditions": [
                  {
                    "id": "5897cde4-1838-4a03-bea9-232d49f6df88",
                    "leftValue": "={{ $('start').item.json.body.modelType }}",
                    "rightValue": "gemini",
                    "operator": {
                      "type": "string",
                      "operation": "equals",
                      "name": "filter.operator.equals"
                    }
                  }
                ],
                "combinator": "and"
              },
              "renameOutput": true,
              "outputKey": "gemini"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.switch",
      "typeVersion": 3.2,
      "position": [
        -320,
        940
      ],
      "id": "8667bd1d-9741-4bfc-b32f-c85d519cf1fb",
      "name": "Switch"
    },
    {
      "parameters": {
        "content": "## OpenAI\nSimply add the API key into the Chat Model. \nIf __no API key__ is available, just insert any placeholder value to proceed.",
        "height": 620,
        "width": 620
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        160,
        -40
      ],
      "id": "b83b7b6a-9b40-4376-9032-150a7bf91c40",
      "name": "Sticky Note3"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "claude-3-7-sonnet-20250219",
          "cachedResultName": "Claude 3.7 Sonnet"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "typeVersion": 1.3,
      "position": [
        340,
        1160
      ],
      "id": "a8208a3c-bd7b-41e4-96c5-8eed27d5ba7f",
      "name": "Anthropic Chat Model1"
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n  \"summary\": \"\",\n  \"agents\": [\n    {\n      \"agentId\": \"\",\n      \"agentName\": \"\",\n      \"content\": \"\"\n    }\n  ]\n}\n"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        520,
        1160
      ],
      "id": "1dde314f-973a-445f-a745-a66244d689f9",
      "name": "Structured Output Parser"
    },
    {
      "parameters": {
        "content": "## Claude\n\nSimply add the API key into the Chat Model. \nIf __no API key__ is available, just insert any placeholder value to proceed.",
        "height": 620,
        "width": 620,
        "color": 5
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        160,
        760
      ],
      "id": "9c7ea518-de27-4918-bff7-b43a7b1b3c50",
      "name": "Sticky Note4"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "gpt-3.5-turbo",
          "mode": "list",
          "cachedResultName": "gpt-3.5-turbo"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        320,
        360
      ],
      "id": "791f4907-7d8f-46e6-9e0c-6a0e58d82fbd",
      "name": "OpenAI Chat Model",
      "credentials": {
        "openAiApi": {
          "id": "WnhCFsAFZPHsGqpO",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n  \"summary\": \"\",\n  \"agents\": [\n    {\n      \"agentId\": \"\",\n      \"agentName\": \"\",\n      \"content\": \"\"\n    }\n  ]\n}\n"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        520,
        360
      ],
      "id": "c590fdb8-43e3-40b2-8a19-8d5d0a51541f",
      "name": "Structured Output Parser1"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $('Process Agent Request').item.json.prompt }}",
        "hasOutputParser": true,
        "messages": {
          "messageValues": [
            {
              "message": "=To maintain context and fully understand the user's question, always review the previous conversation between you and him before providing an answer. Always ensure generating output without s JSON Parsing ERROR.\nThis is the previous conversation: {{ $('Aggregate').item.json[\"context\"].map(m => ` Human: ${m.human || 'undefined'} AI Assistant: ${m.ai || 'undefined'} `).join('') }}"
            }
          ]
        }
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.5,
      "position": [
        340,
        100
      ],
      "id": "219a8138-1426-49fc-b4e5-04081657e988",
      "name": "OpenAI LLM Chain",
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $('Process Agent Request').item.json.prompt }}",
        "hasOutputParser": true,
        "messages": {
          "messageValues": [
            {
              "message": "=To maintain context and fully understand the user's question, always review the previous conversation between you and him before providing an answer. Always ensure generating output without s JSON Parsing ERROR.\nThis is the previous conversation: {{ $('Aggregate').item.json[\"context\"].map(m => ` Human: ${m.human || 'undefined'} AI Assistant: ${m.ai || 'undefined'} `).join('') }}"
            }
          ]
        }
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.5,
      "position": [
        340,
        900
      ],
      "id": "a7ef8f75-d08c-4206-b35b-960be840b530",
      "name": "Claude LLM Chain",
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n  \"summary\": \"\",\n  \"agents\": [\n    {\n      \"agentId\": \"\",\n      \"agentName\": \"\",\n      \"content\": \"\"\n    }\n  ]\n}\n"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        540,
        1920
      ],
      "id": "305e945a-0bdc-4e0e-aa7c-10baaffd4bea",
      "name": "Structured Output Parser2"
    },
    {
      "parameters": {
        "content": "## Ollama",
        "height": 620,
        "width": 620,
        "color": 4
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        160,
        1540
      ],
      "id": "7c48b387-6001-4c4a-8409-bb11cb5948b4",
      "name": "Sticky Note5"
    },
    {
      "parameters": {
        "content": "## Gemini\nAdd your Google API Key credentials to the Chat Model.",
        "height": 620,
        "width": 620
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        160,
        2340
      ],
      "id": "a6b53704-2dbc-4f77-acc4-815345dba169",
      "name": "Sticky Note7"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $('Process Agent Request').item.json.prompt }}",
        "hasOutputParser": true,
        "messages": {
          "messageValues": [
            {
              "message": "=To maintain context and fully understand the user's question, always review the previous conversation between you and him before providing an answer. Always ensure generating output without s JSON Parsing ERROR. Take into account the schema of the parser.\nThis is the previous conversation: {{ $('Aggregate').item.json[\"context\"].map(m => ` Human: ${m.human || 'undefined'} AI Assistant: ${m.ai || 'undefined'} `).join('') }}"
            }
          ]
        }
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.5,
      "position": [
        340,
        2520
      ],
      "id": "e2ad9bb8-d8cc-4985-b5a5-cdaed3b4c1f2",
      "name": "Gemini LLM Chain",
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n  \"summary\": \"\",\n  \"agents\": [\n    {\n      \"agentId\": \"\",\n      \"agentName\": \"\",\n      \"content\": \"\"\n    }\n  ]\n}\n"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        520,
        2740
      ],
      "id": "524c9ec9-1fa8-4d0a-8e1f-f27ddd31d931",
      "name": "Structured Output Parser3"
    },
    {
      "parameters": {
        "modelName": "models/gemini-2.0-flash",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        320,
        2740
      ],
      "id": "eb09c2cd-d4ad-476a-b9cf-9e72a621c36d",
      "name": "Google Gemini Chat Model",
      "credentials": {
        "googlePalmApi": {
          "id": "7C1dNitocYmgSoeE",
          "name": "Google Gemini(PaLM) Api"
        }
      }
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $('Process Agent Request').item.json.prompt }}",
        "hasOutputParser": true,
        "messages": {
          "messageValues": [
            {
              "message": "=To maintain context and fully understand the user's question, always review the previous conversation between you and him before providing an answer. Always ensure generating output without s JSON Parsing ERROR.\nThis is the previous conversation: {{ $('Aggregate').item.json[\"context\"].map(m => ` Human: ${m.human || 'undefined'} AI Assistant: ${m.ai || 'undefined'} `).join('') }}"
            }
          ]
        }
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.5,
      "position": [
        340,
        1680
      ],
      "id": "c460509d-8a81-41d0-8c1a-fc5e7a457509",
      "name": "Ollama LLM Chain",
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "model": "deepseek-r1:7b",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOllama",
      "typeVersion": 1,
      "position": [
        340,
        1920
      ],
      "id": "a97b62b4-ebf1-49ee-b8c8-33c2a5fb01f5",
      "name": "Ollama Chat Model"
    },
    {
      "parameters": {
        "content": "## Prompt reader \nRead the Prompts stored in the dir",
        "height": 360,
        "width": 440
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -3000,
        1160
      ],
      "id": "006f3139-3b95-4abd-8ac8-dfa725c5b66e",
      "name": "Sticky Note6"
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.1,
      "position": [
        -2640,
        1840
      ],
      "id": "94177afe-b45e-4638-8c8d-db5fb8d78815",
      "name": "Healthcheck"
    }
  ],
  "pinData": {
    "start": [
      {
        "json": {
          "headers": {
            "host": "localhost:5678",
            "user-agent": "curl/8.7.1",
            "accept": "*/*",
            "content-type": "application/json",
            "content-length": "186"
          },
          "params": {},
          "query": {},
          "body": {
            "selectedAgentIds": [
              "data-architect",
              "data-engineer"
            ],
            "selectedStrategy": "collaborative",
            "query": "How to design a scalable data pipeline for real-time analytics?"
          },
          "webhookUrl": "http://localhost:5678/webhook/data-engineering-agent",
          "executionMode": "production"
        }
      }
    ]
  },
  "connections": {
    "Process Agent Request": {
      "main": [
        [
          {
            "node": "Chat Memory Manager",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Chat Memory Manager": {
      "main": [
        [
          {
            "node": "Aggregate",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Aggregate": {
      "main": [
        [
          {
            "node": "Switch",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Window Buffer Memory": {
      "ai_memory": [
        [
          {
            "node": "Chat Memory Manager",
            "type": "ai_memory",
            "index": 0
          },
          {
            "node": "Chat Trigger",
            "type": "ai_memory",
            "index": 0
          },
          {
            "node": "Insert Chat",
            "type": "ai_memory",
            "index": 0
          }
        ]
      ]
    },
    "Chat Trigger": {
      "main": [
        [
          {
            "node": "Chat Memory Manager",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "start": {
      "main": [
        [
          {
            "node": "Read/Write Files from Disk",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Healthcheck",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Read/Write Files from Disk": {
      "main": [
        [
          {
            "node": "extract",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "extract": {
      "main": [
        [
          {
            "node": "Process Agent Request",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Switch": {
      "main": [
        [
          {
            "node": "OpenAI LLM Chain",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Claude LLM Chain",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Ollama LLM Chain",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "OpenAI LLM Chain",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Gemini LLM Chain",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Anthropic Chat Model1": {
      "ai_languageModel": [
        [
          {
            "node": "Claude LLM Chain",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Structured Output Parser": {
      "ai_outputParser": [
        [
          {
            "node": "Claude LLM Chain",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "OpenAI LLM Chain",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Structured Output Parser1": {
      "ai_outputParser": [
        [
          {
            "node": "OpenAI LLM Chain",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI LLM Chain": {
      "main": [
        [
          {
            "node": "Respond to Webhook",
            "type": "main",
            "index": 0
          },
          {
            "node": "Insert Chat",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Claude LLM Chain": {
      "main": [
        [
          {
            "node": "Insert Chat",
            "type": "main",
            "index": 0
          },
          {
            "node": "Respond to Webhook",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Structured Output Parser2": {
      "ai_outputParser": [
        [
          {
            "node": "Ollama LLM Chain",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Ollama Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "Ollama LLM Chain",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Ollama LLM Chain": {
      "main": [
        [
          {
            "node": "Respond to Webhook",
            "type": "main",
            "index": 0
          },
          {
            "node": "Insert Chat",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Google Gemini Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "Gemini LLM Chain",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Structured Output Parser3": {
      "ai_outputParser": [
        [
          {
            "node": "Gemini LLM Chain",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Gemini LLM Chain": {
      "main": [
        [
          {
            "node": "Respond to Webhook",
            "type": "main",
            "index": 0
          },
          {
            "node": "Insert Chat",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": true,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "6227f362-32d6-4c8c-b59c-a106ff25982d",
  "meta": {
    "instanceId": "692531ee2a13fa33af74f7a5ea5609474d5a0f7c8c56e5778101f322976ad391"
  },
  "id": "qvRujB5Z7fFaul7f",
  "tags": [
    {
      "createdAt": "2025-04-01T04:51:28.575Z",
      "updatedAt": "2025-04-01T04:51:28.575Z",
      "id": "cOQpbgeAnJqWsyqb",
      "name": "claude"
    },
    {
      "createdAt": "2025-04-01T04:51:28.581Z",
      "updatedAt": "2025-04-01T04:51:28.581Z",
      "id": "lmJWAgftXdqaGCuk",
      "name": "dataengg"
    }
  ]
}